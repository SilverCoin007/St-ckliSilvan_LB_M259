{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Bestimmen Sie, welche Felder Ihrer Daten für Ihr Modell besonders aussagekräftig sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Spalte \"high\", ist die Spalte \"volume\" am wichtigsten. Denn alleine die anderen Spalten sind sonst nutzlos. Mit der Spalte \"volume\" allerdings kann dann eine sinnvolle Berechnung durchgeführt werden, wobei die \"nutzlosen Spalten\" mit der Spalte \"volume\" verrechnet werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Wählen Sie eine geeignete Messmetrik für Ihr Modell und berechnen Sie sie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\silvan.stoeckli\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\silvan.stoeckli\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\silvan.stoeckli\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\silvan.stoeckli\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\silvan.stoeckli\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.22.3)\n",
      "Naive Bayes 0.04\n",
      "Erwartet: 61920, Berechnet: 61920\n",
      "Erwartet: 61912.67, Berechnet: 61912\n",
      "Erwartet: 61907.96, Berechnet: 61907\n"
     ]
    }
   ],
   "source": [
    "%pip install -U scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "bitcoin = os.path.join(\"Datenset_LB_M259 - Demo.csv\")\n",
    "Bitcoin = pd.read_csv(bitcoin)\n",
    "Bitcoin.head()\n",
    "\n",
    "# x = features\n",
    "X = Bitcoin[[\"low\", \"open\", \"close\", \"volume\"]]\n",
    "\n",
    "# y = targets\n",
    "y = Bitcoin[[\"high\"]]\n",
    "X.head()\n",
    "\n",
    "y=y.astype(\"int\")\n",
    "# Dieser Codeabschnitt gibt die Anzahl zeilen zurück die NaN enthalten.\n",
    "len(X[X.isna().any(axis=1)])\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "si = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "si.fit(X)\n",
    "X_ = si.transform(X)\n",
    "X = pd.DataFrame(X_, columns=X.columns)\n",
    "len(X[X.isna().any(axis=1)])\n",
    "# Da die Ausgabe gleich Null ist, muss ich nichts weiteres unternehmen.\n",
    "# Ausserdem habe ich keine NaN Felder. Deshalb muss ich auch da nichts unternehmen.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X, y, test_size = 0.2, random_state = 42\n",
    ")\n",
    "len(X_train), len(X_test)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "algorithms = {\n",
    "    # \"Nearest Neighbors\" : KNeighborsClassifier(3),\n",
    "    # \"Stochastic Gradient Descent\" : SGDClassifier(),\n",
    "    # \"Linear SVM\" : SVC(kernel=\"linear\", C=0.025),\n",
    "    # \"Decision Tree\" : DecisionTreeClassifier(max_depth=5),\n",
    "    # \"Random Forest\" : RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    # \"Neural Net\" : MLPClassifier(alpha=1, max_iter=1000),\n",
    "    \"Naive Bayes\" : GaussianNB(),\n",
    "    # \"LDA\" : LinearDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "\n",
    "for name, algorithm in algorithms.items():\n",
    "    algorithm.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    score = algorithm.score(X_test, y_test)\n",
    "    print(name, round(score,2))\n",
    "\n",
    "    #Medell speichern\n",
    "import joblib\n",
    "joblib.dump(algorithms[\"Naive Bayes\"], 'bitcoin_Naive_Bayes.joblib')\n",
    "best_model = joblib.load('bitcoin_Naive_Bayes.joblib')\n",
    "best_model\n",
    "\n",
    "leo = pd.DataFrame([[61868.81, 61888.18, 61919.98, 2.94607889]], columns=X_train.columns)\n",
    "leo.head()\n",
    "\n",
    "Sahra = pd.DataFrame([[61882.74, 61903.16, 61882.74, 2.94235679]], columns=X_train.columns)\n",
    "Sahra.head()\n",
    "\n",
    "Michelle = pd.DataFrame([[61854.82, 61854.82, 61903.15, 3.0478475]], columns=X_train.columns)\n",
    "Michelle.head()\n",
    "\n",
    "predictions1 = best_model.predict(pd.concat([leo]))\n",
    "for person, prediction1 in zip([\"Leo\"], predictions1):\n",
    "    print(\"Erwartet: 61920, Berechnet:\", prediction1)\n",
    "\n",
    "predictions2 = best_model.predict(pd.concat([Sahra]))\n",
    "for person, prediction2 in zip([\"Sahra\"], predictions2):\n",
    "    print(\"Erwartet: 61912.67, Berechnet:\", prediction2)\n",
    "\n",
    "predictions3 = best_model.predict(pd.concat([Michelle]))\n",
    "for person, prediction3 in zip([\"Michelle\"], predictions3):\n",
    "    print(\"Erwartet: 61907.96, Berechnet:\", prediction3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 28.63 16.5 0.9936186183981285 0.00046159631250597183 0.9936803702685392 2420.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "from sklearn.metrics import max_error\n",
    "\n",
    "\n",
    "print(max_error(predictions1, y_test), mean_absolute_error(predictions1, y_test), median_absolute_error(predictions1, y_test), \n",
    "r2_score(predictions1, y_test), mean_absolute_percentage_error(predictions1, y_test), explained_variance_score(predictions1, y_test), \n",
    "mean_squared_error(predictions1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Wählen Sie geeignete Bedingungen und erstellen Sie eine Wahrheitsmatrix für Ihr Modell. Berechnen Sie darüber hinaus Sensitivität und Spezifizität."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silvan.stoeckli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\silvan.stoeckli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\silvan.stoeckli\\OneDrive - BBBaden\\Desktop\\Informatik\\Lernstrategien\\Modul 259\\StöckliSilvan_LB_M259\\evaluation.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvan.stoeckli/OneDrive%20-%20BBBaden/Desktop/Informatik/Lernstrategien/Modul%20259/St%C3%B6ckliSilvan_LB_M259/evaluation.ipynb#ch0000006?line=24'>25</a>\u001b[0m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m y_test\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvan.stoeckli/OneDrive%20-%20BBBaden/Desktop/Informatik/Lernstrategien/Modul%20259/St%C3%B6ckliSilvan_LB_M259/evaluation.ipynb#ch0000006?line=26'>27</a>\u001b[0m \u001b[39m# calculate null accuracy in a single line of code\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvan.stoeckli/OneDrive%20-%20BBBaden/Desktop/Informatik/Lernstrategien/Modul%20259/St%C3%B6ckliSilvan_LB_M259/evaluation.ipynb#ch0000006?line=27'>28</a>\u001b[0m \u001b[39m# only for binary classification problems coded as 0/1\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/silvan.stoeckli/OneDrive%20-%20BBBaden/Desktop/Informatik/Lernstrategien/Modul%20259/St%C3%B6ckliSilvan_LB_M259/evaluation.ipynb#ch0000006?line=28'>29</a>\u001b[0m \u001b[39mmax\u001b[39;49m(y_test\u001b[39m.\u001b[39;49mmean(), \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m y_test\u001b[39m.\u001b[39;49mmean())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvan.stoeckli/OneDrive%20-%20BBBaden/Desktop/Informatik/Lernstrategien/Modul%20259/St%C3%B6ckliSilvan_LB_M259/evaluation.ipynb#ch0000006?line=30'>31</a>\u001b[0m \u001b[39m# calculate null accuracy (for multi-class classification problems)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/silvan.stoeckli/OneDrive%20-%20BBBaden/Desktop/Informatik/Lernstrategien/Modul%20259/St%C3%B6ckliSilvan_LB_M259/evaluation.ipynb#ch0000006?line=31'>32</a>\u001b[0m y_test\u001b[39m.\u001b[39mvalue_counts()\u001b[39m.\u001b[39mhead(\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:1535\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/silvan.stoeckli/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1532'>1533</a>\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/silvan.stoeckli/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1533'>1534</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/silvan.stoeckli/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1534'>1535</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///c%3A/Users/silvan.stoeckli/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1535'>1536</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/silvan.stoeckli/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1536'>1537</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/silvan.stoeckli/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/generic.py?line=1537'>1538</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "y_test.value_counts()\n",
    "\n",
    "# calculate the percentage of ones\n",
    "# because y_test only contains ones and zeros, we can simply calculate the mean = percentage of ones\n",
    "y_test.mean()\n",
    "\n",
    "# calculate the percentage of zeros\n",
    "1 - y_test.mean()\n",
    "\n",
    "# calculate null accuracy in a single line of code\n",
    "# only for binary classification problems coded as 0/1\n",
    "max(y_test.mean(), 1 - y_test.mean())\n",
    "\n",
    "# calculate null accuracy (for multi-class classification problems)\n",
    "y_test.value_counts().head(1) / len(y_test)\n",
    "\n",
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('False:', y_pred_class[0:25])\n",
    "\n",
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "# this produces a 2x2 numpy array (matrix)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "\n",
    "# print the first 25 true and predicted responses\n",
    "print('True', y_test.values[0:25])\n",
    "print('Pred', y_pred_class[0:25])\n",
    "\n",
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "# use float to perform true division, not integer division\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred_class))\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)\n",
    "\n",
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazit: Für Dieses Datenset ist es nicht möglich die Teilaufgabe 4.3 durchzuführen. Es wird dafür eine Spalte in y benötigt, die nur aus Nullen und Einsen besteht. Oder das man eine Spalte umwandelt. Dies ist allerdings nicht möglich, da mein Datenset keine Spalten hat, wo es logisch wäre die spalten in Nullen und Einsen zu konvertieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Fassen Sie in 50 bis 100 Wörtern zusammen, wie gut Ihr Modell funktioniert, und stellen Sie Hypothesen auf, warum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für Die Aufgaben 1, 2 und 3 ist mein Datenset sehr gut geeignet. Dies liegt wahrscheindlich daran, dasss die Spalten alle einen Zusammenhang haben und nur aus Zahlen bestehen. Die einzige Schwierigkeit ist die Spalte \"time\". Diese habe ich bei der Berechnung einfach nicht beachtet.\n",
    "Für die Teilaufgabe 4 ist mein Datenset nicht so geeignet. Denn diese erfordert eine Spalte in y, die nur aus Nullen und Einsen besteht. Dies war allerdings nicht möglich."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6290412f41753d2501b5150002034550761936216b42d4e1ddd66fe2a0ab9705"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
